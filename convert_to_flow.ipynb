{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "from multiprocessing import Pool\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "_IMAGE_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_for_frames(video_path):\n",
    "    print(video_path)\n",
    "    frames = glob(os.path.join(video_path, '*.png'))\n",
    "    frames.sort()\n",
    "\n",
    "    flow = []\n",
    "    prev = cv2.imread(frames[0])\n",
    "    prev = cv2.cvtColor(prev, cv2.COLOR_BGR2GRAY)\n",
    "    for i, frame_curr in enumerate(frames):\n",
    "        curr = cv2.imread(frame_curr)\n",
    "        curr = cv2.cvtColor(curr, cv2.COLOR_BGR2GRAY)\n",
    "        tmp_flow = compute_TVL1(prev, curr)\n",
    "        flow.append(tmp_flow)\n",
    "        prev = curr\n",
    "\n",
    "    return flow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_TVL1(prev, curr, bound=15):\n",
    "    \"\"\"Compute the TV-L1 optical flow.\"\"\"\n",
    "    TVL1 = cv2.optflow.DualTVL1OpticalFlow_create()\n",
    "    flow = TVL1.calc(prev, curr, None)\n",
    "    #flow_frame = np.clip(flow_frame, -20, 20)\n",
    "    assert flow.dtype == np.float32\n",
    "\n",
    "    flow = (flow + bound) * (255.0 / (2*bound))\n",
    "    flow = np.round(flow).astype(int)\n",
    "    flow[flow >= 255] = 255\n",
    "    flow[flow <= 0] = 0\n",
    "\n",
    "    return flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_flow(video_flows, flow_path):\n",
    "    for i, flow in enumerate(video_flows):\n",
    "        cv2.imwrite(os.path.join(flow_path.format('u'), \"{:06d}.jpg\".format(i)),\n",
    "                    flow[:, :, 0])\n",
    "        cv2.imwrite(os.path.join(flow_path.format('v'), \"{:06d}.jpg\".format(i)),\n",
    "                    flow[:, :, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_flow(args):\n",
    "    video_path, flow_path = args\n",
    "    flow = cal_for_frames(video_path)\n",
    "    save_flow(flow, flow_path)\n",
    "    print('complete:' + flow_path)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_path='/home/lenovo/object-detection/spot-on/I3D/kinetics-i3d/convert_vid2npy/cricket/u/' #This is the path where  images sampled from the video are saved\n",
    "flow_path='/home/lenovo/object-detection/spot-on/I3D/kinetics-i3d/convert_vid2npy/cricket/v' # this is the path where you want save the flow files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lenovo/object-detection/spot-on/I3D/kinetics-i3d/convert_vid2npy/cricket/u/\n"
     ]
    }
   ],
   "source": [
    "# video_path='train/u/' \n",
    "flow = cal_for_frames(frame_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_flow(flow, flow_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert images to .npyfile as descibed in  https://github.com/deepmind/kinetics-i3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "# print(scaler.transform(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_rgb(rgb_path,nchannel):\n",
    "    #print(video_path)\n",
    "    npy_file=[]\n",
    "    frames = glob(os.path.join(rgb_path, '*.png'))\n",
    "    frames.sort()\n",
    "    print(len(frames))\n",
    "    for frame in frames:\n",
    "        img=cv2.imread(os.path.join(frame_path,frame))\n",
    "        img_new=(cv2.resize(img,(224,224))).astype(float)\n",
    "        img_norm=np.divide(2*(img_new-img_new.min()),(img_new.max()-img_new.min()))-1\n",
    "        \n",
    "        npy_file.append(img_norm)\n",
    "        \n",
    "    npy_file=np.reshape(np.asarray(npy_file),(1,len(frames),224,224,nchannel))\n",
    "    np.save('data_input_rgb_cricket.npy',npy_file)\n",
    "    return npy_file\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_flow(flow_path,nchannel):\n",
    "    #print(video_path)\n",
    "    npy_file=[]\n",
    "    frames = glob(os.path.join(flow_path, '*.jpg'))\n",
    "    frames.sort()\n",
    "    print(len(frames))\n",
    "    for frame in frames:\n",
    "        img=cv2.imread(os.path.join(frame_path,frame))\n",
    "        #img=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        img_new=(cv2.resize(img,(224,224))).astype(float)\n",
    "        img_norm=np.divide(2*(img_new-img_new.min()),(img_new.max()-img_new.min()))-1\n",
    "        \n",
    "        npy_file.append(img_norm[:,:,:-1])\n",
    "        \n",
    "    npy_file=np.reshape(np.asarray(npy_file),(1,len(frames),224,224,nchannel-1))\n",
    "    np.save('data_input_flow_cricket.npy',npy_file)\n",
    "    return npy_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n"
     ]
    }
   ],
   "source": [
    "np_file=norm_rgb(frame_path,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lenovo/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:11: RuntimeWarning: invalid value encountered in true_divide\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "np_file=norm_flow(flow_path,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(301, 224, 224, 2)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(np_file).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
